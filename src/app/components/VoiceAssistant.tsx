import React, { useState, useRef, useEffect } from 'react';
import { motion, AnimatePresence } from 'motion/react';
import { 
  Mic, MicOff, Volume2, VolumeX, MessageSquare, Video, 
  Camera, Upload, X, Play, Pause, StopCircle, Send,
  Languages, Phone, RefreshCw, Download, Image as ImageIcon
} from 'lucide-react';
import { Card, CardContent, CardDescription, CardHeader, CardTitle } from './ui/card';
import { Button } from './ui/button';
import { Badge } from './ui/badge';
import { ScrollArea } from './ui/scroll-area';
import { Input } from './ui/input';
import { Tabs, TabsContent, TabsList, TabsTrigger } from './ui/tabs';
import { toast } from 'sonner';
import { projectId, publicAnonKey } from '../../../utils/supabase/info';

interface Message {
  role: 'user' | 'assistant';
  text: string;
  type?: 'text' | 'voice' | 'video' | 'image';
  mediaUrl?: string;
  timestamp?: string;
}

const translations = {
  en: {
    title: 'Smart Voice & Video Assistant',
    subtitle: 'Offline voice support тАв Video crop analysis тАв Multi-language',
    conversation: 'Conversation',
    voiceMode: 'Voice Mode',
    videoMode: 'Video Mode',
    quickQueries: 'Quick Queries',
    offlineMode: 'Offline Mode',
    offlineDesc: 'Works completely offline in rural areas using on-device AI models. No internet required!',
    tapToSpeak: 'Tap to speak',
    listening: 'Listening... Speak now',
    recording: 'Recording video...',
    analyzing: 'Analyzing video...',
    uploadVideo: 'Upload Video',
    recordVideo: 'Record Video',
    takePhoto: 'Take Photo',
    stopRecording: 'Stop Recording',
    sendMessage: 'Send Message',
    typePlaceholder: 'Type your question...',
    videoAnalysis: 'Video Crop Analysis',
    voiceEnabled: 'Voice output enabled',
    voiceDisabled: 'Voice output disabled',
    greeting: 'Namaste! I am your agricultural assistant. How can I help you today?'
  },
  hi: {
    title: 'рд╕реНрдорд╛рд░реНрдЯ рдЖрд╡рд╛рдЬ рдФрд░ рд╡реАрдбрд┐рдпреЛ рд╕рд╣рд╛рдпрдХ',
    subtitle: 'рдСрдлрд▓рд╛рдЗрди рдЖрд╡рд╛рдЬ рд╕рдкреЛрд░реНрдЯ тАв рд╡реАрдбрд┐рдпреЛ рдлрд╕рд▓ рд╡рд┐рд╢реНрд▓реЗрд╖рдг тАв рдмрд╣реБрднрд╛рд╖реА',
    conversation: 'рдмрд╛рддрдЪреАрдд',
    voiceMode: 'рдЖрд╡рд╛рдЬ рдореЛрдб',
    videoMode: 'рд╡реАрдбрд┐рдпреЛ рдореЛрдб',
    quickQueries: 'рддреНрд╡рд░рд┐рдд рдкреНрд░рд╢реНрди',
    offlineMode: 'рдСрдлрд▓рд╛рдЗрди рдореЛрдб',
    offlineDesc: 'рдЧреНрд░рд╛рдореАрдг рдХреНрд╖реЗрддреНрд░реЛрдВ рдореЗрдВ рдкреВрд░реА рддрд░рд╣ рд╕реЗ рдСрдлрд▓рд╛рдЗрди рдХрд╛рдо рдХрд░рддрд╛ рд╣реИред рдЗрдВрдЯрд░рдиреЗрдЯ рдХреА рдЬрд░реВрд░рдд рдирд╣реАрдВ!',
    tapToSpeak: 'рдмреЛрд▓рдиреЗ рдХреЗ рд▓рд┐рдП рдЯреИрдк рдХрд░реЗрдВ',
    listening: 'рд╕реБрди рд░рд╣реЗ рд╣реИрдВ... рдЕрдм рдмреЛрд▓реЗрдВ',
    recording: 'рд╡реАрдбрд┐рдпреЛ рд░рд┐рдХреЙрд░реНрдб рд╣реЛ рд░рд╣рд╛ рд╣реИ...',
    analyzing: 'рд╡реАрдбрд┐рдпреЛ рдХрд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рд╣реЛ рд░рд╣рд╛ рд╣реИ...',
    uploadVideo: 'рд╡реАрдбрд┐рдпреЛ рдЕрдкрд▓реЛрдб рдХрд░реЗрдВ',
    recordVideo: 'рд╡реАрдбрд┐рдпреЛ рд░рд┐рдХреЙрд░реНрдб рдХрд░реЗрдВ',
    takePhoto: 'рдлреЛрдЯреЛ рд▓реЗрдВ',
    stopRecording: 'рд░рд┐рдХреЙрд░реНрдбрд┐рдВрдЧ рдмрдВрдж рдХрд░реЗрдВ',
    sendMessage: 'рд╕рдВрджреЗрд╢ рднреЗрдЬреЗрдВ',
    typePlaceholder: 'рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рд▓рд┐рдЦреЗрдВ...',
    videoAnalysis: 'рд╡реАрдбрд┐рдпреЛ рдлрд╕рд▓ рд╡рд┐рд╢реНрд▓реЗрд╖рдг',
    voiceEnabled: 'рдЖрд╡рд╛рдЬ рдЖрдЙрдЯрдкреБрдЯ рд╕рдХреНрд╖рдо',
    voiceDisabled: 'рдЖрд╡рд╛рдЬ рдЖрдЙрдЯрдкреБрдЯ рдЕрдХреНрд╖рдо',
    greeting: 'рдирдорд╕реНрддреЗ! рдореИрдВ рдЖрдкрдХрд╛ рдХреГрд╖рд┐ рд╕рд╣рд╛рдпрдХ рд╣реВрдВред рдореИрдВ рдЖрдЬ рдЖрдкрдХреА рдХреИрд╕реЗ рдорджрдж рдХрд░ рд╕рдХрддрд╛ рд╣реВрдВ?'
  },
  te: {
    title: 'р░╕р▒Нр░ор░╛р░░р▒Нр░Яр▒Н р░╡р░╛р░пр░┐р░╕р▒Н & р░╡р▒Ар░бр░┐р░пр▒Л р░Ер░╕р░┐р░╕р▒Нр░Яр▒Жр░Вр░Яр▒Н',
    subtitle: 'р░Жр░лр▒НтАМр░▓р▒Ир░ир▒Н р░╡р░╛р░пр░┐р░╕р▒Н р░╕р░кр▒Лр░░р▒Нр░Яр▒Н тАв р░╡р▒Ар░бр░┐р░пр▒Л р░кр░Вр░Я р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г тАв р░мр░╣р▒Бр░нр░╛р░╖р░╛',
    conversation: 'р░╕р░Вр░нр░╛р░╖р░г',
    voiceMode: 'р░╡р░╛р░пр░┐р░╕р▒Н р░ор▒Лр░бр▒Н',
    videoMode: 'р░╡р▒Ар░бр░┐р░пр▒Л р░ор▒Лр░бр▒Н',
    quickQueries: 'р░др▒Нр░╡р░░р░┐р░д р░кр▒Нр░░р░╢р▒Нр░ир░▓р▒Б',
    offlineMode: 'р░Жр░лр▒НтАМр░▓р▒Ир░ир▒Н р░ор▒Лр░бр▒Н',
    offlineDesc: 'р░Чр▒Нр░░р░╛р░ор▒Ар░г р░кр▒Нр░░р░╛р░Вр░др░╛р░▓р▒Нр░▓р▒Л р░кр▒Вр░░р▒Нр░др░┐р░Чр░╛ р░Жр░лр▒НтАМр░▓р▒Ир░ир▒НтАМр░▓р▒Л р░кр░ир░┐р░Ър▒Зр░╕р▒Нр░др▒Бр░Вр░жр░┐. р░Зр░Вр░Яр░░р▒Нр░ир▒Жр░Яр▒Н р░Ер░╡р░╕р░░р░В р░▓р▒Зр░жр▒Б!',
    tapToSpeak: 'р░ор░╛р░Яр▒Нр░▓р░╛р░бр░Яр░╛р░ир░┐р░Хр░┐ р░Яр▒Нр░пр░╛р░кр▒Н р░Ър▒Зр░пр░Вр░бр░┐',
    listening: 'р░╡р░┐р░Вр░Яр▒Бр░ир▒Нр░ир░╛р░В... р░Зр░кр▒Нр░кр▒Бр░бр▒Б р░ор░╛р░Яр▒Нр░▓р░╛р░бр░Вр░бр░┐',
    recording: 'р░╡р▒Ар░бр░┐р░пр▒Л р░░р░┐р░Хр░╛р░░р▒Нр░бр▒Н р░Ер░╡р▒Бр░др▒Лр░Вр░жр░┐...',
    analyzing: 'р░╡р▒Ар░бр░┐р░пр▒Л р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г...',
    uploadVideo: 'р░╡р▒Ар░бр░┐р░пр▒Л р░Ер░кр▒НтАМр░▓р▒Лр░бр▒Н р░Ър▒Зр░пр░Вр░бр░┐',
    recordVideo: 'р░╡р▒Ар░бр░┐р░пр▒Л р░░р░┐р░Хр░╛р░░р▒Нр░бр▒Н р░Ър▒Зр░пр░Вр░бр░┐',
    takePhoto: 'р░лр▒Лр░Яр▒Л р░др▒Ар░пр░Вр░бр░┐',
    stopRecording: 'р░░р░┐р░Хр░╛р░░р▒Нр░бр░┐р░Вр░Чр▒Н р░Жр░кр░Вр░бр░┐',
    sendMessage: 'р░╕р░Вр░жр▒Зр░╢р░В р░кр░Вр░кр░Вр░бр░┐',
    typePlaceholder: 'р░ор▒А р░кр▒Нр░░р░╢р▒Нр░ир░ир▒Б р░Яр▒Ир░кр▒Н р░Ър▒Зр░пр░Вр░бр░┐...',
    videoAnalysis: 'р░╡р▒Ар░бр░┐р░пр▒Л р░кр░Вр░Я р░╡р░┐р░╢р▒Нр░▓р▒Зр░╖р░г',
    voiceEnabled: 'р░╡р░╛р░пр░┐р░╕р▒Н р░Ер░╡р▒Бр░Яр▒НтАМр░кр▒Бр░Яр▒Н р░кр▒Нр░░р░╛р░░р░Вр░нр░┐р░Вр░Ър░мр░бр░┐р░Вр░жр░┐',
    voiceDisabled: 'р░╡р░╛р░пр░┐р░╕р▒Н р░Ер░╡р▒Бр░Яр▒НтАМр░кр▒Бр░Яр▒Н р░ир░┐р░▓р░┐р░кр░┐р░╡р▒Зр░пр░мр░бр░┐р░Вр░жр░┐',
    greeting: 'р░ир░ор░╕р▒Нр░Хр░╛р░░р░В! р░ир▒Зр░ир▒Б р░ор▒А р░╡р▒Нр░пр░╡р░╕р░╛р░п р░╕р░╣р░╛р░пр░Хр▒Бр░бр░ир▒Б. р░Ир░░р▒Лр░Ьр▒Б р░ир▒Зр░ир▒Б р░ор▒Ар░Хр▒Б р░Ор░▓р░╛ р░╕р░╣р░╛р░пр░В р░Ър▒Зр░пр░Чр░▓р░ир▒Б?'
  },
  ta: {
    title: 'ро╕рпНрооро╛ро░рпНроЯрпН роХрпБро░ро▓рпН & ро╡рпАроЯро┐ропрпЛ роЙродро╡ро┐ропро╛ро│ро░рпН',
    subtitle: 'роЖроГрокрпНро▓рпИройрпН роХрпБро░ро▓рпН роЖродро░ро╡рпБ тАв ро╡рпАроЯро┐ропрпЛ рокропро┐ро░рпН рокроХрпБрокрпНрокро╛ропрпНро╡рпБ тАв рокро▓ роорпКро┤ро┐',
    conversation: 'роЙро░рпИропро╛роЯро▓рпН',
    voiceMode: 'роХрпБро░ро▓рпН рокропройрпНроорпБро▒рпИ',
    videoMode: 'ро╡рпАроЯро┐ропрпЛ рокропройрпНроорпБро▒рпИ',
    quickQueries: 'ро╡ро┐ро░рпИро╡рпБ роХрпЗро│рпНро╡ро┐роХро│рпН',
    offlineMode: 'роЖроГрокрпНро▓рпИройрпН рокропройрпНроорпБро▒рпИ',
    offlineDesc: 'роХро┐ро░ро╛роорокрпНрокрпБро▒ рокроХрпБродро┐роХро│ро┐ро▓рпН роорпБро┤рпБро╡родрпБрооро╛роХ роЖроГрокрпНро▓рпИройро┐ро▓рпН ро╡рпЗро▓рпИ роЪрпЖропрпНроХро┐ро▒родрпБ. роЗрогрпИропроорпН родрпЗро╡рпИропро┐ро▓рпНро▓рпИ!',
    tapToSpeak: 'рокрпЗроЪ родроЯрпНроЯро╡рпБроорпН',
    listening: 'роХрпЗроЯрпНроХро┐ро▒родрпБ... роЗрокрпНрокрпЛродрпБ рокрпЗроЪрпБроЩрпНроХро│рпН',
    recording: 'ро╡рпАроЯро┐ропрпЛ рокродро┐ро╡рпБ роЪрпЖропрпНропрокрпНрокроЯрпБроХро┐ро▒родрпБ...',
    analyzing: 'ро╡рпАроЯро┐ропрпЛ рокроХрпБрокрпНрокро╛ропрпНро╡рпБ...',
    uploadVideo: 'ро╡рпАроЯро┐ропрпЛро╡рпИ рокродро┐ро╡рпЗро▒рпНро▒ро╡рпБроорпН',
    recordVideo: 'ро╡рпАроЯро┐ропрпЛро╡рпИ рокродро┐ро╡рпБ роЪрпЖропрпНропро╡рпБроорпН',
    takePhoto: 'рокрпБроХрпИрокрпНрокроЯроорпН роОроЯрпБроХрпНроХро╡рпБроорпН',
    stopRecording: 'рокродро┐ро╡рпИ роиро┐ро▒рпБродрпНродро╡рпБроорпН',
    sendMessage: 'роЪрпЖропрпНродро┐ роЕройрпБрокрпНрокро╡рпБроорпН',
    typePlaceholder: 'роЙроЩрпНроХро│рпН роХрпЗро│рпНро╡ро┐ропрпИ родроЯрпНроЯроЪрпНроЪрпБ роЪрпЖропрпНропро╡рпБроорпН...',
    videoAnalysis: 'ро╡рпАроЯро┐ропрпЛ рокропро┐ро░рпН рокроХрпБрокрпНрокро╛ропрпНро╡рпБ',
    voiceEnabled: 'роХрпБро░ро▓рпН ро╡рпЖро│ро┐ропрпАроЯрпБ роЗропроХрпНроХрокрпНрокроЯрпНроЯродрпБ',
    voiceDisabled: 'роХрпБро░ро▓рпН ро╡рпЖро│ро┐ропрпАроЯрпБ роорпБроЯроХрпНроХрокрпНрокроЯрпНроЯродрпБ',
    greeting: 'ро╡рогроХрпНроХроорпН! роиро╛ройрпН роЙроЩрпНроХро│рпН ро╡ро┐ро╡роЪро╛роп роЙродро╡ро┐ропро╛ро│ро░рпН. роЗройрпНро▒рпБ роиро╛ройрпН роЙроЩрпНроХро│рпБроХрпНроХрпБ роОрокрпНрокроЯро┐ роЙродро╡ роорпБроЯро┐ропрпБроорпН?'
  },
  mr: {
    title: 'рд╕реНрдорд╛рд░реНрдЯ рд╡реНрд╣реЙрдЗрд╕ рдЖрдгрд┐ рд╡реНрд╣рд┐рдбрд┐рдУ рд╕рд╣рд╛рдпреНрдпрдХ',
    subtitle: 'рдСрдлрд▓рд╛рдЗрди рд╡реНрд╣реЙрдЗрд╕ рд╕рдкреЛрд░реНрдЯ тАв рд╡реНрд╣рд┐рдбрд┐рдУ рдкреАрдХ рд╡рд┐рд╢реНрд▓реЗрд╖рдг тАв рдмрд╣реБрднрд╛рд╖рд┐рдХ',
    conversation: 'рд╕рдВрднрд╛рд╖рдг',
    voiceMode: 'рд╡реНрд╣реЙрдЗрд╕ рдореЛрдб',
    videoMode: 'рд╡реНрд╣рд┐рдбрд┐рдУ рдореЛрдб',
    quickQueries: 'рдЬрд▓рдж рдкреНрд░рд╢реНрди',
    offlineMode: 'рдСрдлрд▓рд╛рдЗрди рдореЛрдб',
    offlineDesc: 'рдЧреНрд░рд╛рдореАрдг рднрд╛рдЧрд╛рдд рдкреВрд░реНрдгрдкрдгреЗ рдСрдлрд▓рд╛рдЗрди рдХрд╛рдо рдХрд░рддреЗ. рдЗрдВрдЯрд░рдиреЗрдЯрдЪреА рдЧрд░рдЬ рдирд╛рд╣реА!',
    tapToSpeak: 'рдмреЛрд▓рдгреНрдпрд╛рд╕рд╛рдареА рдЯреЕрдк рдХрд░рд╛',
    listening: 'рдРрдХрдд рдЖрд╣реЗ... рдЖрддрд╛ рдмреЛрд▓рд╛',
    recording: 'рд╡реНрд╣рд┐рдбрд┐рдУ рд░реЗрдХреЙрд░реНрдб рд╣реЛрдд рдЖрд╣реЗ...',
    analyzing: 'рд╡реНрд╣рд┐рдбрд┐рдУ рд╡рд┐рд╢реНрд▓реЗрд╖рдг рдХрд░рдд рдЖрд╣реЗ...',
    uploadVideo: 'рд╡реНрд╣рд┐рдбрд┐рдУ рдЕрдкрд▓реЛрдб рдХрд░рд╛',
    recordVideo: 'рд╡реНрд╣рд┐рдбрд┐рдУ рд░реЗрдХреЙрд░реНрдб рдХрд░рд╛',
    takePhoto: 'рдлреЛрдЯреЛ рдХрд╛рдврд╛',
    stopRecording: 'рд░реЗрдХреЙрд░реНрдбрд┐рдВрдЧ рдерд╛рдВрдмрд╡рд╛',
    sendMessage: 'рд╕рдВрджреЗрд╢ рдкрд╛рдард╡рд╛',
    typePlaceholder: 'рддреБрдордЪрд╛ рдкреНрд░рд╢реНрди рдЯрд╛рдЗрдк рдХрд░рд╛...',
    videoAnalysis: 'рд╡реНрд╣рд┐рдбрд┐рдУ рдкреАрдХ рд╡рд┐рд╢реНрд▓реЗрд╖рдг',
    voiceEnabled: 'рд╡реНрд╣реЙрдЗрд╕ рдЖрдЙрдЯрдкреБрдЯ рд╕рдХреНрд╖рдо',
    voiceDisabled: 'рд╡реНрд╣реЙрдЗрд╕ рдЖрдЙрдЯрдкреБрдЯ рдЕрдХреНрд╖рдо',
    greeting: 'рдирдорд╕реНрдХрд╛рд░! рдореА рддреБрдордЪрд╛ рдХреГрд╖реА рд╕рд╣рд╛рдпреНрдпрдХ рдЖрд╣реЗ. рдЖрдЬ рдореА рддреБрдореНрд╣рд╛рд▓рд╛ рдХрд╢реА рдорджрдд рдХрд░реВ рд╢рдХрддреЛ?'
  },
  kn: {
    title: 'р▓╕р│Нр▓ор▓╛р▓░р│Нр▓Яр│Н р▓зр│Нр▓╡р▓ир▓┐ р▓ор▓др│Нр▓др│Б р▓╡р│Ар▓бр▓┐р▓пр│К р▓╕р▓╣р▓╛р▓пр▓Х',
    subtitle: 'р▓Жр▓лр│НтАМр▓▓р│Ир▓ир│Н р▓зр│Нр▓╡р▓ир▓┐ р▓мр│Жр▓Вр▓мр▓▓ тАв р▓╡р│Ар▓бр▓┐р▓пр│К р▓мр│Жр▓│р│Ж р▓╡р▓┐р▓╢р│Нр▓▓р│Зр▓╖р▓гр│Ж тАв р▓мр▓╣р│Б р▓нр▓╛р▓╖р│Ж',
    conversation: 'р▓╕р▓Вр▓╡р▓╛р▓ж',
    voiceMode: 'р▓зр│Нр▓╡р▓ир▓┐ р▓ор│Лр▓бр│Н',
    videoMode: 'р▓╡р│Ар▓бр▓┐р▓пр│К р▓ор│Лр▓бр│Н',
    quickQueries: 'р▓др│Нр▓╡р▓░р▓┐р▓д р▓кр│Нр▓░р▓╢р│Нр▓ир│Жр▓Чр▓│р│Б',
    offlineMode: 'р▓Жр▓лр│НтАМр▓▓р│Ир▓ир│Н р▓ор│Лр▓бр│Н',
    offlineDesc: 'р▓Чр│Нр▓░р▓╛р▓ор│Ар▓г р▓кр│Нр▓░р▓жр│Зр▓╢р▓Чр▓│р▓▓р│Нр▓▓р▓┐ р▓╕р▓Вр▓кр│Вр▓░р│Нр▓гр▓╡р▓╛р▓Чр▓┐ р▓Жр▓лр│НтАМр▓▓р│Ир▓ир│НтАМр▓ир▓▓р│Нр▓▓р▓┐ р▓Хр▓╛р▓░р│Нр▓пр▓ир▓┐р▓░р│Нр▓╡р▓╣р▓┐р▓╕р│Бр▓др│Нр▓др▓жр│Ж. р▓Зр▓Вр▓Яр▓░р│Нр▓ир│Жр▓Яр│Н р▓Ер▓Чр▓др│Нр▓пр▓╡р▓┐р▓▓р│Нр▓▓!',
    tapToSpeak: 'р▓ор▓╛р▓др▓ир▓╛р▓бр▓▓р│Б р▓Яр│Нр▓пр▓╛р▓кр│Н р▓ор▓╛р▓бр▓┐',
    listening: 'р▓Хр│Зр▓│р│Бр▓др│Нр▓др▓┐р▓жр│Ж... р▓Ир▓Ч р▓ор▓╛р▓др▓ир▓╛р▓бр▓┐',
    recording: 'р▓╡р│Ар▓бр▓┐р▓пр│К р▓░р│Жр▓Хр▓╛р▓░р│Нр▓бр│Н р▓Жр▓Чр│Бр▓др│Нр▓др▓┐р▓жр│Ж...',
    analyzing: 'р▓╡р│Ар▓бр▓┐р▓пр│К р▓╡р▓┐р▓╢р│Нр▓▓р│Зр▓╖р▓гр│Ж...',
    uploadVideo: 'р▓╡р│Ар▓бр▓┐р▓пр│К р▓Ер▓кр│НтАМр▓▓р│Лр▓бр│Н р▓ор▓╛р▓бр▓┐',
    recordVideo: 'р▓╡р│Ар▓бр▓┐р▓пр│К р▓░р│Жр▓Хр▓╛р▓░р│Нр▓бр│Н р▓ор▓╛р▓бр▓┐',
    takePhoto: 'р▓лр│Лр▓Яр│Л р▓др│Жр▓Чр│Жр▓пр▓┐р▓░р▓┐',
    stopRecording: 'р▓░р│Жр▓Хр▓╛р▓░р│Нр▓бр▓┐р▓Вр▓Чр│Н р▓ир▓┐р▓▓р│Нр▓▓р▓┐р▓╕р▓┐',
    sendMessage: 'р▓╕р▓Вр▓жр│Зр▓╢ р▓Хр▓│р│Бр▓╣р▓┐р▓╕р▓┐',
    typePlaceholder: 'р▓ир▓┐р▓ор│Нр▓о р▓кр│Нр▓░р▓╢р│Нр▓ир│Жр▓пр▓ир│Нр▓ир│Б р▓Яр│Ир▓кр│Н р▓ор▓╛р▓бр▓┐...',
    videoAnalysis: 'р▓╡р│Ар▓бр▓┐р▓пр│К р▓мр│Жр▓│р│Ж р▓╡р▓┐р▓╢р│Нр▓▓р│Зр▓╖р▓гр│Ж',
    voiceEnabled: 'р▓зр│Нр▓╡р▓ир▓┐ р▓Фр▓Яр│НтАМр▓кр│Бр▓Яр│Н р▓╕р▓Хр│Нр▓░р▓┐р▓пр▓Чр│Кр▓│р▓┐р▓╕р▓▓р▓╛р▓Чр▓┐р▓жр│Ж',
    voiceDisabled: 'р▓зр│Нр▓╡р▓ир▓┐ р▓Фр▓Яр│НтАМр▓кр│Бр▓Яр│Н р▓ир▓┐р▓╖р│Нр▓Хр│Нр▓░р▓┐р▓пр▓Чр│Кр▓│р▓┐р▓╕р▓▓р▓╛р▓Чр▓┐р▓жр│Ж',
    greeting: 'р▓ир▓ор▓╕р│Нр▓Хр▓╛р▓░! р▓ир▓╛р▓ир│Б р▓ир▓┐р▓ор│Нр▓о р▓Хр│Гр▓╖р▓┐ р▓╕р▓╣р▓╛р▓пр▓Х. р▓Зр▓Вр▓жр│Б р▓ир▓╛р▓ир│Б р▓ир▓┐р▓ор▓Чр│Ж р▓╣р│Зр▓Чр│Ж р▓╕р▓╣р▓╛р▓п р▓ор▓╛р▓бр▓мр▓╣р│Бр▓жр│Б?'
  }
};

export default function VoiceAssistant({ language }: { language: string }) {
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const [inputText, setInputText] = useState('');
  const [videoPreview, setVideoPreview] = useState<string | null>(null);
  const [mode, setMode] = useState<'voice' | 'video' | 'text'>('voice');
  const [activeTab, setActiveTab] = useState('voice');
  
  const videoRef = useRef<HTMLVideoElement>(null);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const fileInputRef = useRef<HTMLInputElement>(null);
  const photoInputRef = useRef<HTMLInputElement>(null);

  const t = translations[language as keyof typeof translations] || translations.en;

  useEffect(() => {
    // Add initial greeting message
    if (messages.length === 0) {
      setMessages([{ 
        role: 'assistant', 
        text: t.greeting,
        type: 'text',
        timestamp: new Date().toISOString()
      }]);
    }
  }, []);

  // Voice Recognition
  const toggleListening = async () => {
    if (!isListening) {
      setIsListening(true);
      toast.success(t.listening);
      
      // Simulate voice recognition with Web Speech API
      try {
        // In production, use: const recognition = new webkitSpeechRecognition();
        // For demo, simulate after 2 seconds
        setTimeout(() => {
          const farmerQuestions = [
            'What fertilizer should I use for rice?',
            'When should I irrigate my crops?',
            'How can I prevent pests in wheat?',
            'What is the market price for cotton today?',
            'Tell me about PM-KISAN scheme',
            'How to increase crop yield?',
            'Best time to sow maize?',
            'Organic farming tips'
          ];
          const question = farmerQuestions[Math.floor(Math.random() * farmerQuestions.length)];
          
          setMessages(prev => [...prev, { 
            role: 'user', 
            text: question,
            type: 'voice',
            timestamp: new Date().toISOString()
          }]);
          setIsListening(false);

          // Generate AI response
          setTimeout(() => {
            const response = generateResponse(question);
            setMessages(prev => [...prev, { 
              role: 'assistant', 
              text: response,
              type: 'text',
              timestamp: new Date().toISOString()
            }]);
            
            // Speak response if enabled
            if (isSpeaking) {
              speakText(response);
            }
          }, 1000);
        }, 2000);
      } catch (error) {
        console.error('Voice recognition error:', error);
        toast.error('Voice recognition not supported');
        setIsListening(false);
      }
    } else {
      setIsListening(false);
      toast.info('Stopped listening');
    }
  };

  // Text to Speech
  const speakText = (text: string) => {
    if ('speechSynthesis' in window) {
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.lang = language === 'hi' ? 'hi-IN' : language === 'te' ? 'te-IN' : language === 'ta' ? 'ta-IN' : 'en-IN';
      utterance.rate = 0.9;
      utterance.pitch = 1;
      window.speechSynthesis.speak(utterance);
      toast.info('Reading response...');
    }
  };

  const toggleSpeech = () => {
    setIsSpeaking(!isSpeaking);
    toast.success(isSpeaking ? t.voiceDisabled : t.voiceEnabled);
  };

  // Video Recording
  const startVideoRecording = async () => {
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: { facingMode: 'environment' }, 
        audio: true 
      });
      
      if (videoRef.current) {
        videoRef.current.srcObject = stream;
        videoRef.current.play();
      }

      const mediaRecorder = new MediaRecorder(stream);
      mediaRecorderRef.current = mediaRecorder;
      
      const chunks: Blob[] = [];
      mediaRecorder.ondataavailable = (e) => chunks.push(e.data);
      
      mediaRecorder.onstop = async () => {
        const blob = new Blob(chunks, { type: 'video/webm' });
        const videoUrl = URL.createObjectURL(blob);
        setVideoPreview(videoUrl);
        
        // Stop all tracks
        stream.getTracks().forEach(track => track.stop());
        
        // Analyze video for crop health/pest detection
        await analyzeVideo(blob);
      };

      mediaRecorder.start();
      setIsRecording(true);
      toast.success(t.recording);
    } catch (error) {
      console.error('Video recording error:', error);
      toast.error('Camera access denied or not available');
    }
  };

  const stopVideoRecording = () => {
    if (mediaRecorderRef.current && isRecording) {
      mediaRecorderRef.current.stop();
      setIsRecording(false);
      toast.info('Recording stopped');
    }
  };

  // Video Upload
  const handleVideoUpload = (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file && file.type.startsWith('video/')) {
      const videoUrl = URL.createObjectURL(file);
      setVideoPreview(videoUrl);
      analyzeVideo(file);
    } else {
      toast.error('Please select a valid video file');
    }
  };

  // Photo Upload
  const handlePhotoUpload = async (e: React.ChangeEvent<HTMLInputElement>) => {
    const file = e.target.files?.[0];
    if (file && file.type.startsWith('image/')) {
      const imageUrl = URL.createObjectURL(file);
      
      setMessages(prev => [...prev, { 
        role: 'user', 
        text: 'Uploaded crop photo for analysis',
        type: 'image',
        mediaUrl: imageUrl,
        timestamp: new Date().toISOString()
      }]);

      // Simulate image analysis
      toast.info('Analyzing image...');
      setTimeout(() => {
        const analysis = analyzeImage();
        setMessages(prev => [...prev, { 
          role: 'assistant', 
          text: analysis,
          type: 'text',
          timestamp: new Date().toISOString()
        }]);
      }, 2000);
    }
  };

  // Analyze uploaded video
  const analyzeVideo = async (videoBlob: Blob | File) => {
    toast.info(t.analyzing);
    
    setMessages(prev => [...prev, { 
      role: 'user', 
      text: 'Uploaded crop video for analysis',
      type: 'video',
      mediaUrl: videoPreview || URL.createObjectURL(videoBlob as Blob),
      timestamp: new Date().toISOString()
    }]);

    // Simulate AI video analysis
    setTimeout(() => {
      const analysis = `ЁЯОе Video Analysis Results:

тЬЕ Crop Health Status: Good (NDVI: 0.75)
ЁЯМ▒ Growth Stage: Vegetative (Day 45)
ЁЯТз Moisture Level: Adequate (78%)
ЁЯРЫ Pest Detection: 2 aphids detected in sector B
ЁЯНВ Leaf Discoloration: Minor yellowing (3% area)

ЁЯУК Recommendations:
тАв Apply neem oil spray for aphid control
тАв Monitor nitrogen levels - slight deficiency detected
тАв Maintain current irrigation schedule
тАв Expect harvest in 35-40 days

ЁЯУН Analyzed Area: 2.5 acres
тП▒я╕П Analysis Time: 3.2 seconds`;

      setMessages(prev => [...prev, { 
        role: 'assistant', 
        text: analysis,
        type: 'text',
        timestamp: new Date().toISOString()
      }]);

      if (isSpeaking) {
        speakText('Video analysis complete. Good crop health detected with minor aphid presence.');
      }
    }, 3000);
  };

  // Analyze uploaded image
  const analyzeImage = () => {
    const diseases = ['Leaf Blight', 'Bacterial Spot', 'Healthy', 'Powdery Mildew', 'Rust'];
    const detected = diseases[Math.floor(Math.random() * diseases.length)];
    
    if (detected === 'Healthy') {
      return `ЁЯУ╖ Image Analysis: Your crop appears HEALTHY! тЬЕ\n\nNo diseases detected. Continue current care routine.`;
    } else {
      return `ЁЯУ╖ Image Analysis: ${detected} detected тЪая╕П\n\nConfidence: 87%\n\nTreatment:\nтАв Apply appropriate fungicide\nтАв Remove affected leaves\nтАв Improve air circulation\nтАв Reduce humidity\n\nPrevention:\nтАв Use resistant varieties\nтАв Practice crop rotation\nтАв Maintain field hygiene`;
    }
  };

  // Generate AI response
  const generateResponse = (question: string) => {
    const q = question.toLowerCase();
    
    if (q.includes('fertilizer') || q.includes('npk')) {
      return `For ${q.includes('rice') ? 'rice' : 'general'} cultivation:\n\nЁЯМ╛ Vegetative Stage:\nтАв NPK 20:10:10 - 150kg/acre\nтАв Apply 15 days after planting\n\nЁЯМ╕ Flowering Stage:\nтАв NPK 10:20:20 - 100kg/acre\nтАв Apply at flower initiation\n\nЁЯТ░ Cost: тВ╣3,500-4,500/acre\nЁЯУИ Expected Yield Increase: 20-25%`;
    }
    
    if (q.includes('irrigate') || q.includes('water')) {
      return `ЁЯТз Irrigation Schedule:\n\nЁЯМ▒ Vegetative: Every 3 days\nЁЯМ╕ Flowering: Every 2 days\nЁЯМ╛ Grain Filling: Every 4 days\n\nЁЯТб Tips:\nтАв Irrigate early morning (6-8 AM)\nтАв Maintain 2-3 inches standing water for rice\nтАв Use drip irrigation to save 40% water\nтАв Check soil moisture before watering`;
    }
    
    if (q.includes('pest') || q.includes('insect')) {
      return `ЁЯРЫ Organic Pest Control:\n\nтЬЕ Neem Oil Spray:\nтАв 5ml neem oil per liter water\nтАв Spray weekly, early morning\n\nтЬЕ Yellow Sticky Traps:\nтАв Install 8-10 per acre\nтАв Replace every 2 weeks\n\nтЬЕ Biological Control:\nтАв Introduce ladybugs for aphids\nтАв Use Trichogramma for stem borer\n\nЁЯФм For severe infestation, contact local agriculture officer`;
    }
    
    if (q.includes('price') || q.includes('market')) {
      return `ЁЯТ░ Current Market Prices (Today):\n\nЁЯМ╛ Rice: тВ╣2,100/quintal (тЖС 8%)\nЁЯМ╛ Wheat: тВ╣2,050/quintal (тЖТ stable)\nЁЯМ╛ Cotton: тВ╣5,800/quintal (тЖС 12%)\n\nЁЯУИ Best Time to Sell:\nтАв Rice: Next 2-3 weeks (price rising)\nтАв Cotton: Sell now (peak price)\n\nЁЯУН Best Market: District Mandi (15km)\nЁЯТб Register on e-NAM for better prices`;
    }
    
    if (q.includes('scheme') || q.includes('subsidy') || q.includes('pm-kisan')) {
      return `ЁЯПЫя╕П Government Benefits:\n\nтЬЕ PM-KISAN: тВ╣6,000/year\nтАв Direct bank transfer\nтАв Apply: pmkisan.gov.in\n\nтЬЕ PMFBY Insurance:\nтАв 2% premium for Kharif\nтАв Covers natural disasters\n\nтЬЕ Soil Health Card:\nтАв Free soil testing\nтАв Visit nearest KVK\n\nЁЯУЮ Helpline: 1800-180-1551`;
    }
    
    if (q.includes('yield') || q.includes('production')) {
      return `ЁЯУК Yield Increase Strategies:\n\n1я╕ПтГг Precision Agriculture (AI)\nтАв Use our yield prediction tool\nтАв 20-30% increase expected\n\n2я╕ПтГг Quality Seeds\nтАв Use certified hybrid seeds\nтАв 15% yield boost\n\n3я╕ПтГг Balanced Fertilization\nтАв Soil testing first\nтАв Apply based on NPK levels\n\n4я╕ПтГг Pest Management\nтАв Early detection crucial\nтАв Use integrated approach\n\nЁЯТб Total potential increase: 50-70%`;
    }
    
    return `I can help you with:\n\nЁЯМ╛ Crop Management\nЁЯТ░ Market Prices\nЁЯРЫ Pest Control\nЁЯТз Irrigation Planning\nЁЯПЫя╕П Government Schemes\nЁЯУК Yield Predictions\nЁЯОе Video Crop Analysis\n\nPlease ask a specific question!`;
  };

  // Send text message
  const handleSendMessage = () => {
    if (inputText.trim()) {
      setMessages(prev => [...prev, { 
        role: 'user', 
        text: inputText,
        type: 'text',
        timestamp: new Date().toISOString()
      }]);

      const response = generateResponse(inputText);
      
      setTimeout(() => {
        setMessages(prev => [...prev, { 
          role: 'assistant', 
          text: response,
          type: 'text',
          timestamp: new Date().toISOString()
        }]);

        if (isSpeaking) {
          speakText(response);
        }
      }, 1000);

      setInputText('');
    }
  };

  const quickQueries = [
    'Soil testing',
    'Pest control',
    'Market prices',
    'Weather forecast',
    'Irrigation tips',
    'Government schemes',
    'Crop rotation',
    'Yield prediction'
  ];

  return (
    <div className="space-y-6">
      <div>
        <h2 className="text-3xl font-bold text-gray-800 flex items-center gap-3">
          <Video className="w-8 h-8 text-purple-600" />
          {t.title}
        </h2>
        <p className="text-gray-600 mt-2">{t.subtitle}</p>
      </div>

      <Tabs value={activeTab} onValueChange={setActiveTab} className="w-full">
        <TabsList className="grid w-full grid-cols-2">
          <TabsTrigger value="voice" className="flex items-center gap-2">
            <Mic className="w-4 h-4" />
            {t.voiceMode}
          </TabsTrigger>
          <TabsTrigger value="video" className="flex items-center gap-2">
            <Video className="w-4 h-4" />
            {t.videoMode}
          </TabsTrigger>
        </TabsList>

        <TabsContent value="voice" className="mt-6">
          <div className="grid grid-cols-1 lg:grid-cols-3 gap-6">
            <Card className="lg:col-span-2 border-none shadow-lg">
              <CardHeader>
                <div className="flex items-center justify-between">
                  <CardTitle>{t.conversation}</CardTitle>
                  <div className="flex gap-2">
                    <Button
                      variant="outline"
                      size="sm"
                      onClick={toggleSpeech}
                      className={isSpeaking ? 'bg-green-50' : ''}
                    >
                      {isSpeaking ? <Volume2 className="w-4 h-4" /> : <VolumeX className="w-4 h-4" />}
                    </Button>
                    <Badge variant="outline" className="bg-green-50">
                      <Languages className="w-3 h-3 mr-1" />
                      {language.toUpperCase()}
                    </Badge>
                  </div>
                </div>
              </CardHeader>
              <CardContent>
                <ScrollArea className="h-96 pr-4">
                  <div className="space-y-4">
                    {messages.map((msg, idx) => (
                      <motion.div
                        key={idx}
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        className={`flex ${msg.role === 'user' ? 'justify-end' : 'justify-start'}`}
                      >
                        <div className={`max-w-[80%] rounded-2xl px-4 py-3 ${
                          msg.role === 'user' 
                            ? 'bg-gradient-to-r from-green-500 to-emerald-600 text-white' 
                            : 'bg-gray-100 text-gray-800'
                        }`}>
                          {msg.type === 'image' && msg.mediaUrl && (
                            <img src={msg.mediaUrl} alt="Uploaded" className="rounded-lg mb-2 max-w-full" />
                          )}
                          {msg.type === 'video' && msg.mediaUrl && (
                            <video src={msg.mediaUrl} controls className="rounded-lg mb-2 max-w-full" />
                          )}
                          <p className="text-sm whitespace-pre-line">{msg.text}</p>
                          {msg.type === 'voice' && (
                            <Badge className="mt-2 bg-white/20">
                              <Mic className="w-3 h-3 mr-1" />
                              Voice
                            </Badge>
                          )}
                        </div>
                      </motion.div>
                    ))}
                  </div>
                </ScrollArea>

                <div className="mt-6 space-y-4">
                  {/* Voice Button */}
                  <div className="flex justify-center">
                    <motion.button
                      whileTap={{ scale: 0.95 }}
                      onClick={toggleListening}
                      className={`relative w-20 h-20 rounded-full flex items-center justify-center shadow-lg transition-all ${
                        isListening 
                          ? 'bg-gradient-to-r from-red-500 to-pink-600' 
                          : 'bg-gradient-to-r from-purple-500 to-indigo-600'
                      }`}
                    >
                      {isListening ? (
                        <MicOff className="w-8 h-8 text-white" />
                      ) : (
                        <Mic className="w-8 h-8 text-white" />
                      )}

                      <AnimatePresence>
                        {isListening && (
                          <>
                            <motion.div
                              initial={{ scale: 1, opacity: 0.5 }}
                              animate={{ scale: 2, opacity: 0 }}
                              exit={{ scale: 1, opacity: 0 }}
                              transition={{ duration: 1.5, repeat: Infinity }}
                              className="absolute inset-0 rounded-full bg-red-500"
                            />
                            <motion.div
                              initial={{ scale: 1, opacity: 0.5 }}
                              animate={{ scale: 2.5, opacity: 0 }}
                              exit={{ scale: 1, opacity: 0 }}
                              transition={{ duration: 1.5, repeat: Infinity, delay: 0.3 }}
                              className="absolute inset-0 rounded-full bg-pink-500"
                            />
                          </>
                        )}
                      </AnimatePresence>
                    </motion.button>
                  </div>

                  <p className="text-center text-sm text-gray-600">
                    {isListening ? t.listening : t.tapToSpeak}
                  </p>

                  {/* Text Input */}
                  <div className="flex gap-2">
                    <Input
                      value={inputText}
                      onChange={(e) => setInputText(e.target.value)}
                      onKeyPress={(e) => e.key === 'Enter' && handleSendMessage()}
                      placeholder={t.typePlaceholder}
                      className="flex-1"
                    />
                    <Button onClick={handleSendMessage} className="bg-gradient-to-r from-green-500 to-emerald-600">
                      <Send className="w-4 h-4" />
                    </Button>
                  </div>

                  {/* Photo Upload */}
                  <div className="flex gap-2">
                    <input
                      ref={photoInputRef}
                      type="file"
                      accept="image/*"
                      onChange={handlePhotoUpload}
                      className="hidden"
                    />
                    <Button
                      variant="outline"
                      onClick={() => photoInputRef.current?.click()}
                      className="flex-1"
                    >
                      <ImageIcon className="w-4 h-4 mr-2" />
                      {t.takePhoto}
                    </Button>
                  </div>
                </div>
              </CardContent>
            </Card>

            <div className="space-y-6">
              <Card className="border-none shadow-lg">
                <CardHeader>
                  <CardTitle className="text-sm">{t.quickQueries}</CardTitle>
                </CardHeader>
                <CardContent className="space-y-2">
                  {quickQueries.map((query, idx) => (
                    <Button
                      key={idx}
                      variant="outline"
                      size="sm"
                      className="w-full justify-start text-left"
                      onClick={() => {
                        setInputText(query);
                        handleSendMessage();
                      }}
                    >
                      <MessageSquare className="w-3 h-3 mr-2" />
                      {query}
                    </Button>
                  ))}
                </CardContent>
              </Card>

              <Card className="border-none shadow-lg bg-gradient-to-br from-purple-500 to-indigo-600 text-white">
                <CardHeader>
                  <CardTitle className="text-sm">{t.offlineMode}</CardTitle>
                </CardHeader>
                <CardContent>
                  <p className="text-sm opacity-90">{t.offlineDesc}</p>
                </CardContent>
              </Card>
            </div>
          </div>
        </TabsContent>

        <TabsContent value="video" className="mt-6">
          <div className="grid grid-cols-1 lg:grid-cols-2 gap-6">
            {/* Video Recording/Upload */}
            <Card className="border-none shadow-lg">
              <CardHeader>
                <CardTitle>{t.videoAnalysis}</CardTitle>
                <CardDescription>
                  Record or upload crop video for AI-powered health analysis
                </CardDescription>
              </CardHeader>
              <CardContent className="space-y-4">
                {/* Video Preview */}
                <div className="aspect-video bg-gray-100 rounded-lg overflow-hidden flex items-center justify-center">
                  {isRecording ? (
                    <video ref={videoRef} className="w-full h-full object-cover" muted />
                  ) : videoPreview ? (
                    <video src={videoPreview} controls className="w-full h-full object-cover" />
                  ) : (
                    <div className="text-center text-gray-400">
                      <Video className="w-16 h-16 mx-auto mb-2" />
                      <p className="text-sm">No video selected</p>
                    </div>
                  )}
                </div>

                {/* Video Controls */}
                <div className="grid grid-cols-2 gap-3">
                  {!isRecording ? (
                    <>
                      <Button
                        onClick={startVideoRecording}
                        className="bg-gradient-to-r from-red-500 to-pink-600"
                      >
                        <Camera className="w-4 h-4 mr-2" />
                        {t.recordVideo}
                      </Button>
                      <Button
                        variant="outline"
                        onClick={() => fileInputRef.current?.click()}
                      >
                        <Upload className="w-4 h-4 mr-2" />
                        {t.uploadVideo}
                      </Button>
                      <input
                        ref={fileInputRef}
                        type="file"
                        accept="video/*"
                        onChange={handleVideoUpload}
                        className="hidden"
                      />
                    </>
                  ) : (
                    <Button
                      onClick={stopVideoRecording}
                      className="col-span-2 bg-gradient-to-r from-red-500 to-pink-600"
                    >
                      <StopCircle className="w-4 h-4 mr-2" />
                      {t.stopRecording}
                    </Button>
                  )}
                </div>

                {videoPreview && (
                  <Button
                    variant="outline"
                    onClick={() => setVideoPreview(null)}
                    className="w-full"
                  >
                    <RefreshCw className="w-4 h-4 mr-2" />
                    Clear & Record New
                  </Button>
                )}
              </CardContent>
            </Card>

            {/* Analysis Results */}
            <Card className="border-none shadow-lg">
              <CardHeader>
                <CardTitle>Analysis Results</CardTitle>
              </CardHeader>
              <CardContent>
                <ScrollArea className="h-96">
                  <div className="space-y-4">
                    {messages.filter(m => m.type === 'video' || (m.role === 'assistant' && messages.some(msg => msg.type === 'video'))).map((msg, idx) => (
                      <motion.div
                        key={idx}
                        initial={{ opacity: 0, y: 10 }}
                        animate={{ opacity: 1, y: 0 }}
                        className="bg-gray-50 rounded-lg p-4"
                      >
                        <p className="text-sm whitespace-pre-line">{msg.text}</p>
                      </motion.div>
                    ))}
                    
                    {messages.filter(m => m.type === 'video').length === 0 && (
                      <div className="text-center text-gray-400 py-12">
                        <Video className="w-16 h-16 mx-auto mb-4" />
                        <p className="text-sm">Upload or record a video to see analysis</p>
                      </div>
                    )}
                  </div>
                </ScrollArea>
              </CardContent>
            </Card>
          </div>
        </TabsContent>
      </Tabs>
    </div>
  );
}
